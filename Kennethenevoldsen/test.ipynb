{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from numba import jit, cuda \n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "import Dataloader as dl\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask\n",
    "\n",
    "# Loads data and returns a list of sentences as specfies in Dataloader\n",
    "sentences = dl.loaddata()\n",
    "\n",
    "# Load AutoModel from huggingface model repository\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"KennethEnevoldsen/dfm-sentence-encoder-large\")\n",
    "model = AutoModel.from_pretrained(\"KennethEnevoldsen/dfm-sentence-encoder-large\")\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(\n",
    "    sentences, padding=True, truncation=True, max_length=128, return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling. In this case, mean pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "\n",
    "sentence_embeddings = sentence_embeddings.detach().numpy()\n",
    "\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "tsne_results = tsne.fit_transform(sentence_embeddings)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(tsne_results[:,0], tsne_results[:,1])\n",
    "plt.title('t-SNE of Sentence Embeddings')\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
